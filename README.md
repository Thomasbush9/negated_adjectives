# 🔍 Exploring Negation and Antonymy in Sentence Embeddings

This project investigates how negated adjectives are represented in embedding spaces and whether these representations align more with their affirmatives or antonyms. We use both classical distributional methods and deep generative models.

## 🧪 Experiments
- **Experiment 1**: Neural network over Word2Vec embeddings to learn semantic relationships.
- **Experiment 2**: Sentence Variational Autoencoder (VAE) trained on real and synthetic reviews to explore latent space arithmetic.

## 📁 Folder Structure

code/
├── vae.py # Sentence VAE architecture
├── model_building/ # Custom NN layers and training scripts
├── data_augmentation/ # Synthetic data generation
├── data_preparation/ # Dataset filtering and formatting

## 📝 Marimo Notebooks
Interactive experiments and result analysis were built with [Marimo notebooks](https://github.com/marimo-team/marimo) for reproducibility and clarity.

